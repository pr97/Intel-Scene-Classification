{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_log_dir='X:/train-scene classification/logs_resnet50_vanilla' # Change for every new training session \n",
    "\n",
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir=use_log_dir, **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        training_log_dir = os.path.join(log_dir, 'training')\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "train_data_dir = \"X:/train-scene classification/data/train/\"\n",
    "validation_data_dir = \"X:/train-scene classification/data/valid/\"\n",
    "test_data_dir = \"X:/train-scene classification/data/test/\"\n",
    "nb_train_samples = 16384\n",
    "nb_validation_samples = 650 \n",
    "batch_size = 32\n",
    "epochs = 1000\n",
    "# Save the model according to the conditions  \n",
    "chkpt_dir = \"X:/train-scene classification/chkpts/resnet50_vanilla.h5\" # Change for every new training session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResNet50(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3), classes = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('resnet50.h5')\n",
    "model = load_model('resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "# for layer in model.layers[:200]:\n",
    "#     layer.trainable = False\n",
    "\n",
    "model.summary()\n",
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers[3].get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(2048, activation=\"relu\")(x)\n",
    "x = Dropout(0.7)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(6, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If resuming training (and the notebook hasn't been closed after the previous training session), run code from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.load_weights(chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=10)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=10)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "# chkpt_dir = \"X:/train-scene classification/chkpts/densenet_extra_fc.h5\" # Change for every new training session \n",
    "\n",
    "checkpoint = ModelCheckpoint(chkpt_dir, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=40, verbose=1, mode='auto')\n",
    "#[TrainValTensorBoard(write_graph=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "train_generator,\n",
    "samples_per_epoch = nb_train_samples,\n",
    "epochs = epochs,\n",
    "validation_data = validation_generator,\n",
    "nb_val_samples = nb_validation_samples,\n",
    "callbacks = [checkpoint, early, TrainValTensorBoard(write_graph=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Model\n",
    "model_final.save(\"vgg_vanilla.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing + Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode=\"rgb\",\n",
    "        shuffle = False,\n",
    "        class_mode='categorical',\n",
    "        batch_size=1)\n",
    "\n",
    "filenames = test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "\n",
    "predict = model.predict_generator(test_generator,steps = nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_learning_phase(0) #For setting inference phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = load_model(chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "test_data_dir_2 = \"X:/train-scene classification/data/test/final_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train_generator.class_indices)\n",
    "\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "print(labels)\n",
    "# predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"X:/train-scene classification/data/train/0_buildings\"\n",
    "img = cv2.imread(os.path.join(train_dir, \"146.jpg\"))\n",
    "\n",
    "# valid_dir = \"X:/train-scene classification/data/valid/0_buildings\"\n",
    "# img = cv2.imread(os.path.join(valid_dir, \"2800.jpg\"))\n",
    "\n",
    "# img = cv2.imread(os.path.join(test_data_dir_2, \"398.jpg\"))\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_rgb)\n",
    "print(img.shape)\n",
    "img = np.reshape(img, (1, img_width, img_height, 3))\n",
    "img = img / 255.\n",
    "pred = np.argmax(model_final.predict(img), axis=1)\n",
    "print(pred, labels[pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### model = load_model(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_generator = test_datagen.flow_from_directory(\n",
    "#     directory=\"X:/train-scene classification/data/test/\",\n",
    "#     target_size=(img_width, img_height),\n",
    "#     color_mode=\"rgb\",\n",
    "#     batch_size=1,\n",
    "#     class_mode=None,\n",
    "#     shuffle=False,\n",
    "#     seed=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_generator.reset()\n",
    "# pred=model_final.predict_generator(test_generator,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# predicted_class_indices=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predicted_class_indices[:20])\n",
    "# print(predicted_class_indices.shape)\n",
    "# print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(os.path.join(\"X:/train-scene classification\", 'test_images.csv'))\n",
    "print(df.head())\n",
    "test_list = df.image_name.values\n",
    "print(test_list[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "join_l = []\n",
    "ans = []\n",
    "test_data_dir_2 = \"X:/train-scene classification/data/test/final_test\"\n",
    "for i, im in enumerate(test_list):\n",
    "    img = cv2.imread(os.path.join(test_data_dir_2, im))\n",
    "    if i == 1:\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img_rgb)\n",
    "    img = cv2.resize(img, (img_width, img_height)) \n",
    "    img = np.reshape(img, (1, img_width, img_height, 3))\n",
    "    img = img / 255.\n",
    "    pred = np.argmax(model_final.predict(img), axis=1)\n",
    "    ans.append((im, pred))\n",
    "\n",
    "# x_test = np.vstack(join_l)\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "join_l = []\n",
    "ans = []\n",
    "test_data_dir_2 = \"X:/train-scene classification/data/test/final_test\"\n",
    "'''\n",
    "for i, im in enumerate(test_list):\n",
    "    img = cv2.imread(os.path.join(test_data_dir_2, im))\n",
    "    img = cv2.resize(img, (img_width, img_height)) \n",
    "    img = np.reshape(img, (1, img_width, img_height, 3))\n",
    "    pred = np.argmax(model_final.predict(img), axis=1)\n",
    "    ans.append((im, pred))\n",
    "'''\n",
    "\n",
    "for i in range(0, len(test_list), 32):\n",
    "    j = i\n",
    "    batch = []\n",
    "    for j in range(i, i+32):\n",
    "        if(j>=len(test_list)):\n",
    "            break\n",
    "        img = cv2.imread(os.path.join(test_data_dir_2, test_list[j]))\n",
    "        img = cv2.resize(img, (img_width, img_height)) \n",
    "        img = np.reshape(img, (1, img_width, img_height, 3))\n",
    "        batch.append(img)\n",
    "    batch = np.vstack(batch)\n",
    "    pred = np.argmax(model_final.predict(batch), axis=1)\n",
    "    for j in range(i, i+32):\n",
    "        if(j>=len(test_list)):\n",
    "            break\n",
    "        ans.append((test_list[j], pred[j-i]))\n",
    "print(ans[:10])\n",
    "# x_test = np.vstack(join_l)\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for i in ans:\n",
    "    pa = i[0]\n",
    "    val= i[1][0]\n",
    "    li.append([pa, val])\n",
    "print(li[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(li, columns=[\"image_name\", \"label\"])\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('submission_resnet50_corrected_normalized.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dlenv)",
   "language": "python",
   "name": "dlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
